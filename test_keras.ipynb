{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b73f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import IterableDataset, DataLoader, get_worker_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86003f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "(32, 1, 64)\n"
     ]
    }
   ],
   "source": [
    ">>> model = tf.keras.Sequential()\n",
    ">>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=1))\n",
    ">>> # The model will take as input an integer matrix of size (batch,\n",
    ">>> # input_length), and the largest integer (i.e. word index) in the input\n",
    ">>> # should be no larger than 999 (vocabulary size).\n",
    ">>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    ">>> # dimension.\n",
    ">>> input_array = np.random.randint(1000, size=(32, 1))\n",
    ">>> model.compile('rmsprop', 'mse')\n",
    ">>> output_array = model.predict(input_array)\n",
    ">>> print(output_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c71cedb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.62717798e-03,  2.62365825e-02,  4.83096726e-02,\n",
       "         3.49922106e-03,  4.45561744e-02,  4.20769304e-03,\n",
       "         3.59562524e-02,  3.16233672e-02,  1.31273158e-02,\n",
       "        -1.43897645e-02,  2.66341679e-02, -8.28067213e-03,\n",
       "         4.65450920e-02,  2.81646363e-02,  4.21465151e-02,\n",
       "        -4.70392779e-03,  1.91234089e-02,  2.91728042e-02,\n",
       "        -7.22243637e-03,  6.20406866e-03,  7.63901323e-03,\n",
       "         1.62975900e-02, -4.66045737e-02, -3.06449085e-03,\n",
       "         3.55370082e-02, -2.67876312e-03, -7.55916908e-03,\n",
       "         4.82646115e-02,  3.78613546e-03, -7.57617876e-03,\n",
       "        -4.12671193e-02, -5.58657572e-03,  2.47048773e-02,\n",
       "        -1.12726204e-02, -2.64335424e-04, -9.28055122e-03,\n",
       "         3.52434255e-02, -4.12894413e-03,  3.75962295e-02,\n",
       "        -2.23878510e-02, -2.92806271e-02, -4.51295152e-02,\n",
       "        -1.09318718e-02,  7.24419951e-05,  4.47081961e-02,\n",
       "        -4.40355800e-02,  2.07252540e-02, -4.64570522e-03,\n",
       "         2.15801261e-02,  1.97724439e-02,  4.44864146e-02,\n",
       "         4.56664674e-02,  1.47318877e-02,  4.00209688e-02,\n",
       "         1.52465366e-02, -1.61528587e-05,  3.22283022e-02,\n",
       "         4.28083874e-02, -4.32493091e-02, -2.48943921e-02,\n",
       "        -3.50863561e-02, -1.24667287e-02,  4.57227565e-02,\n",
       "         3.47961523e-02]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d9a789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 64, 512):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b75811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetTriplePair(IterableDataset):\n",
    "    def __init__(self, item_size, user_list, pair, shuffle, num_epochs):\n",
    "        self.item_size = item_size\n",
    "        self.user_list = user_list\n",
    "        self.pair = pair\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.example_size = self.num_epochs * len(self.pair)\n",
    "        self.example_index_queue = deque([])\n",
    "        self.seed = 0\n",
    "        self.start_list_index = None\n",
    "        self.num_workers = 1\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= self.example_size:\n",
    "            raise StopIteration\n",
    "        # If `example_index_queue` is used up, replenish this list.\n",
    "        while len(self.example_index_queue) == 0:\n",
    "            index_list = list(range(len(self.pair)))\n",
    "            if self.shuffle:\n",
    "                random.Random(self.seed).shuffle(index_list)\n",
    "                self.seed += 1\n",
    "            if self.start_list_index is not None:\n",
    "                index_list = index_list[self.start_list_index::self.num_workers]\n",
    "\n",
    "                # Calculate next start index\n",
    "                self.start_list_index = (self.start_list_index + (self.num_workers - (len(self.pair) % self.num_workers))) % self.num_workers\n",
    "            self.example_index_queue.extend(index_list)\n",
    "        result = self._example(self.example_index_queue.popleft())\n",
    "        self.index += self.num_workers\n",
    "        return result\n",
    "\n",
    "    def _example(self, idx):\n",
    "        u = self.pair[idx][0]\n",
    "        i = self.pair[idx][1]\n",
    "        j = np.random.randint(self.item_size)\n",
    "        while j in self.user_list[u]:\n",
    "            j = np.random.randint(self.item_size)\n",
    "        return u, i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd3d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/vuhoang/Documents/code_base/APR-PyTorch/preprocessed/ml-1m.pickle', 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "        user_size, item_size = dataset['user_size'], dataset['item_size']\n",
    "        train_user_list, test_user_list = dataset['train_user_list'], dataset['test_user_list']\n",
    "        train_pair = dataset['train_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd4beca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GetTriplePair(item_size, train_user_list, train_pair, True, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03bceb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GetTriplePair at 0x7f9c27a81f40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca38e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51347cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f9c27a81dc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9def9282",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deque' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:378\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_BaseDataLoaderIter\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 378\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SingleProcessDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:666\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset, (IterDataPipe, MapDataPipe)):\n\u001b[1;32m    664\u001b[0m     torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgraph_settings\u001b[38;5;241m.\u001b[39mapply_sharding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_world_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rank)\n\u001b[0;32m--> 666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher \u001b[38;5;241m=\u001b[39m \u001b[43m_DatasetKind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_fetcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_kind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_collation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_last\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:80\u001b[0m, in \u001b[0;36m_DatasetKind.create_fetcher\u001b[0;34m(kind, dataset, auto_collation, collate_fn, drop_last)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _utils\u001b[38;5;241m.\u001b[39mfetch\u001b[38;5;241m.\u001b[39m_MapDatasetFetcher(dataset, auto_collation, collate_fn, drop_last)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_IterableDatasetFetcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_collation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:23\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.__init__\u001b[0;34m(self, dataset, auto_collation, collate_fn, drop_last)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, auto_collation, collate_fn, drop_last):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_IterableDatasetFetcher, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     21\u001b[0m         dataset, auto_collation, collate_fn, drop_last\n\u001b[1;32m     22\u001b[0m     )\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [8], line 11\u001b[0m, in \u001b[0;36mGetTriplePair.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexample_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpair)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexample_index_queue \u001b[38;5;241m=\u001b[39m \u001b[43mdeque\u001b[49m([])\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_list_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deque' is not defined"
     ]
    }
   ],
   "source": [
    "print(list(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
